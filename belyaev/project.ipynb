{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import typing\n",
    "from dataclasses import dataclass, field\n",
    "import warnings\n",
    "from contextlib import contextmanager\n",
    "import itertools\n",
    "import functools\n",
    "import logging\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional\n",
    "import transformers\n",
    "import transformers.modeling_outputs\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def localize_globals(*exceptions: str, restore_values: bool = True):\n",
    "    exceptions: typing.Set[str] = set(exceptions)\n",
    "\n",
    "    old_globals: typing.Dict[str, typing.Any] = dict(globals())\n",
    "    allowed: typing.Set[str] = set(old_globals.keys())\n",
    "    allowed.update(exceptions)\n",
    "\n",
    "    yield None\n",
    "\n",
    "    new_globals: typing.Dict[str, typing.Any] = globals()\n",
    "\n",
    "    for name in tuple(new_globals.keys()):\n",
    "        if name not in allowed:\n",
    "            del new_globals[name]\n",
    "    \n",
    "    if not restore_values:\n",
    "        return\n",
    "    \n",
    "    new_globals.update(\n",
    "        {k: v for k, v in old_globals.items() if k not in exceptions}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"[{levelname}] {message}\",\n",
    "    style=\"{\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>one_liner</th>\n",
       "      <th>long_description</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wufoo</td>\n",
       "      <td>Online form builder.</td>\n",
       "      <td>Wufoo is a web application that helps anybody ...</td>\n",
       "      <td>[SaaS, Productivity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Project Wedding</td>\n",
       "      <td></td>\n",
       "      <td>Finding wedding vendors is hard. In 2007, a co...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clustrix</td>\n",
       "      <td></td>\n",
       "      <td>Clustrix provides the leading scale-out relati...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inkling</td>\n",
       "      <td></td>\n",
       "      <td>Inkling, based in Chicago, Illinois, offers co...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Audiobeta</td>\n",
       "      <td></td>\n",
       "      <td>AudioBeta develops web-based applications that...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name             one_liner  \\\n",
       "0            Wufoo  Online form builder.   \n",
       "1  Project Wedding                         \n",
       "2         Clustrix                         \n",
       "3          Inkling                         \n",
       "4        Audiobeta                         \n",
       "\n",
       "                                    long_description                  tags  \n",
       "0  Wufoo is a web application that helps anybody ...  [SaaS, Productivity]  \n",
       "1  Finding wedding vendors is hard. In 2007, a co...                    []  \n",
       "2  Clustrix provides the leading scale-out relati...                    []  \n",
       "3  Inkling, based in Chicago, Illinois, offers co...                    []  \n",
       "4  AudioBeta develops web-based applications that...                    []  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data: pd.DataFrame = pd.read_csv(\"yc_essential_data.csv\")\n",
    "\n",
    "# Limit to the columns we're interested in\n",
    "data = data[[\"name\", \"one_liner\", \"long_description\", \"tags\"]]\n",
    "\n",
    "# Convert tags to a list\n",
    "data[\"tags\"] = data[\"tags\"].apply(literal_eval)\n",
    "assert isinstance(data.at[0, \"tags\"], list), \"Didn't work!\"\n",
    "\n",
    "# Okay, apparently an empty string makes a nan by default\n",
    "# Gotta reverse it\n",
    "data[\"one_liner\"].replace(\n",
    "    to_replace=np.nan,\n",
    "    value=\"\",\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "data[\"long_description\"].replace(\n",
    "    to_replace=np.nan,\n",
    "    value=\"\",\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Preview the results\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          3D Printed Foods\n",
       "1               3D Printing\n",
       "2                        AI\n",
       "3              AI Assistant\n",
       "4      AI-Enhanced Learning\n",
       "               ...         \n",
       "324          Women's Health\n",
       "325     Workflow Automation\n",
       "326               eLearning\n",
       "327                 eSports\n",
       "328                    web3\n",
       "Length: 329, dtype: object"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gather all unique tags\n",
    "with localize_globals(\"all_tags\"):\n",
    "    tags_set: set[str] = set(itertools.chain.from_iterable(data[\"tags\"]))\n",
    "    \n",
    "    all_tags: pd.Series = pd.Series(sorted(tags_set))\n",
    "\n",
    "all_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer: transformers.DistilBertTokenizer = transformers.DistilBertTokenizer.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    ")\n",
    "\n",
    "nlp_model: transformers.DistilBertModel = transformers.DistilBertModel.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS: int = 512\n",
    "EMBEDDING_SIZE: int = 768"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539230e4b08143609388d1a1dfeb086d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4423 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['name', 'one_liner', 'long_description', 'tags'],\n",
       "    num_rows: 4423\n",
       "})"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with localize_globals(\"complete_dataset\", \"col_pad_len\"):\n",
    "    complete_dataset = datasets.Dataset.from_pandas(data).with_format(\"torch\")\n",
    "    \n",
    "    def tokenize(row: dict[str, typing.Any]) -> dict[str, typing.Any]:\n",
    "        for column in (\n",
    "            \"name\",\n",
    "            \"one_liner\",\n",
    "            \"long_description\",\n",
    "        ):\n",
    "            row[f\"{column}\"] = tokenizer(\n",
    "                row[column],\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=MAX_TOKENS,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "        \n",
    "        row[\"tags\"] = torch.tensor(all_tags.apply(row[\"tags\"].__contains__), dtype=torch.float)\n",
    "        \n",
    "        return row\n",
    "    \n",
    "    complete_dataset = complete_dataset.map(tokenize)\n",
    "\n",
    "complete_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['name', 'one_liner', 'long_description', 'tags'],\n",
       "     num_rows: 3538\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['name', 'one_liner', 'long_description', 'tags'],\n",
       "     num_rows: 619\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['name', 'one_liner', 'long_description', 'tags'],\n",
       "     num_rows: 266\n",
       " }))"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with localize_globals(\"train_dataset\", \"test_dataset\", \"val_dataset\"):\n",
    "    train_test_split = complete_dataset.train_test_split(test_size=0.2)\n",
    "    train_dataset = train_test_split[\"train\"]\n",
    "    \n",
    "    test_val_split = train_test_split[\"test\"].train_test_split(test_size=0.3)\n",
    "    test_dataset = test_val_split[\"train\"]\n",
    "    val_dataset = test_val_split[\"test\"]\n",
    "\n",
    "train_dataset, test_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiInputModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes multiple inputs from named columns of a dataset,\n",
    "    passes them to separate sub-modules, and collects the\n",
    "    result with a single collector module.\n",
    "    \n",
    "    Note: the arguments are passed to the collector by\n",
    "    their order, the names are only used for column selection.\n",
    "    This behaviour relies on nn.ModuleDict preserving the\n",
    "    order of insertion, which should hold for Python >= 3.6.\n",
    "    If that's not the case, you'll get arbitrary but consistent (?)\n",
    "    order within a single `MultiInputModule` instance.\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs: nn.ModuleDict\n",
    "    collector: nn.Module\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        inputs: nn.ModuleDict,\n",
    "        collector: nn.Module,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.collector = collector\n",
    "        self.inputs = inputs\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        input_dict: typing.Mapping[str, torch.Tensor],\n",
    "    ) -> torch.Tensor:\n",
    "        assert set(input_dict.keys()).issuperset(self.inputs.keys()), \\\n",
    "            f\"Missing parameters: expected {set(self.inputs.keys())}, got only {set(input_dict.keys())}\"\n",
    "        \n",
    "        return self.collector(*(\n",
    "            self.inputs[name](input_dict[name])\n",
    "            for name in self.inputs\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatenationModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes a list of tensors and concatenates them\n",
    "    into a single tensor along a new axis\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        *tensors: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        return torch.cat(tensors, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KwargsMapModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes a dictionary an `**`-unwraps it for the submodule's input\n",
    "    \"\"\"\n",
    "    \n",
    "    submodule: nn.Module\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        submodule: nn.Module,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.submodule = submodule\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        params: typing.Mapping[str, torch.Tensor],\n",
    "    ) -> torch.Tensor:\n",
    "        return self.submodule(**params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLPWrapperModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Wraps an nlp module and performs the following pre- and postprocessing:\n",
    "    - Takes a dictionary and `**`-unwraps it for the submodule's input\n",
    "    - Takes `.last_hidden_state` from the submodule's result and returns only it\n",
    "    \"\"\"\n",
    "    \n",
    "    submodule: nn.Module\n",
    "    \n",
    "    def __init__(self, submodule: nn.Module) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.submodule = submodule\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        params: typing.Mapping[str, torch.Tensor],\n",
    "    ) -> torch.Tensor:\n",
    "        return self.submodule(**params).last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "with localize_globals(\"model\"):\n",
    "    input_embedder: nn.Module = NLPWrapperModule(nlp_model)\n",
    "    # I can't afford to also tune BERT, nor do I need to\n",
    "    input_embedder.train(False)\n",
    "\n",
    "    model: nn.Module = nn.Sequential(\n",
    "        MultiInputModule(\n",
    "            inputs=nn.ModuleDict(dict(\n",
    "                name=input_embedder,\n",
    "                one_liner=input_embedder,\n",
    "                long_description=input_embedder,\n",
    "            )),\n",
    "            collector=ConcatenationModule(),\n",
    "        ),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(\n",
    "            in_features=EMBEDDING_SIZE * MAX_TOKENS * 3,\n",
    "            out_features=len(all_tags),\n",
    "        ),\n",
    "        nn.Softmax(dim=-1),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] actual_shape=torch.Size([329]), target_shape=torch.Size([329])\n"
     ]
    }
   ],
   "source": [
    "with localize_globals():\n",
    "    actual_shape = model(train_dataset[0])[0].shape \n",
    "    target_shape = train_dataset[0][\"tags\"].shape\n",
    "    \n",
    "    logging.info(f\"{actual_shape=}, {target_shape=}\")\n",
    "    \n",
    "    assert actual_shape == target_shape, \"Bad model result shape\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
